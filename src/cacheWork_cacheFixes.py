"""
File: cacheFixes.py
Description:
    Used to redo batches that failed from createCache.py in smaller increments
    Can then be repeated again for smaller and smaller increment

Usage:
    run two commands for correct usage:
    python cacheFixes.py --init
    python cacheFixes.py
"""

import pandas as pd
import datetime as dt
import sys
import pirep as pr
from dateutil import parser
import pickle

"""
Examples of how to format the batches that failed
"""
# erroredDates = [
#     ("2017-04-05 12:00:00+00:00", "2017-04-06 00:00:00+00:00"),
#     ("2017-09-03 12:00:00.001000+00:00 ", "2017-09-04 00:00:00+00:00"),
#     ("2018-02-25 12:00:00.001000+00:00 ", "2018-02-26 00:00:00+00:00"),
#     ("2018-12-07 12:00:00.001000+00:00 ", "2018-12-08 00:00:00+00:00"),
#     ("2018-12-13 12:00:00.001000+00:00 ", "2018-12-14 00:00:00+00:00"),
#     ("2019-01-01 12:00:00.001000+00:00 ", "2019-01-02 00:00:00+00:00"),
#     ("2019-02-26 00:00:00.001000+00:00 ", "2019-02-26 12:00:00+00:00"),
#     ("2019-04-30 12:00:00.001000+00:00 ", "2019-05-01 00:00:00+00:00"),
#     ("2019-05-21 12:00:00.001000+00:00 ", "2019-05-22 00:00:00+00:00"),
#     ("2020-03-18 12:00:00.001000+00:00 ", "2020-03-19 00:00:00+00:00"),
#     ("2020-09-16 12:00:00.001000+00:00 ", "2020-09-17 00:00:00+00:00"),
#     ("2020-10-02 00:00:00.001000+00:00 ", "2020-10-02 12:00:00+00:00"),
#     ("2021-01-27 12:00:00.001000+00:00 ", "2021-01-28 00:00:00+00:00"),
#     ("2021-04-01 12:00:00.001000+00:00 ", "2021-04-02 00:00:00+00:00"),
#     ("2021-05-02 12:00:00.001000+00:00 ", "2021-05-03 00:00:00+00:00"),
#     ("2021-06-06 12:00:00.001000+00:00 ", "2021-06-07 00:00:00+00:00"),
#     ("2021-06-12 12:00:00.001000+00:00 ", "2021-06-13 00:00:00+00:00"),
#     ("2021-06-19 12:00:00.001000+00:00 ", "2021-06-20 00:00:00+00:00"),
#     ("2021-11-13 12:00:00.001000+00:00 ", "2021-11-14 00:00:00+00:00"),
#     ("2021-12-06 12:00:00.001000+00:00 ", "2021-12-07 00:00:00+00:00"),
#     ("2021-12-21 12:00:00.001000+00:00 ", "2021-12-22 00:00:00+00:00"),
#     ("2022-02-22 00:00:00.001000+00:00 ", "2022-02-22 12:00:00+00:00"),
#     ("2022-04-03 12:00:00.001000+00:00 ", "2022-04-04 00:00:00+00:00"),
#     ("2022-04-15 00:00:00.001000+00:00 ", "2022-04-15 12:00:00+00:00"),
#     ("2022-04-16 12:00:00.001000+00:00 ", "2022-04-17 00:00:00+00:00"),
#     ("2022-06-20 12:00:00.001000+00:00 ", "2022-06-21 00:00:00+00:00"),
#     ("2022-07-12 12:00:00.001000+00:00 ", "2022-07-13 00:00:00+00:00"),
#     ("2022-08-06 12:00:00.001000+00:00 ", "2022-08-07 00:00:00+00:00"),
#     ("2022-08-16 12:00:00.001000+00:00 ", "2022-08-17 00:00:00+00:00"),
#     ("2022-09-18 12:00:00.001000+00:00 ", "2022-09-19 00:00:00+00:00"),
#     ("2022-11-03 12:00:00.001000+00:00 ", "2022-11-04 00:00:00+00:00"),
#     ("2022-11-17 12:00:00.001000+00:00 ", "2022-11-18 00:00:00+00:00"),
#     ("2022-11-19 12:00:00.001000+00:00 ", "2022-11-20 00:00:00+00:00"),
#     ("2022-12-03 12:00:00.001000+00:00 ", "2022-12-04 00:00:00+00:00"),
#     ("2022-12-20 00:00:00.001000+00:00 ", "2022-12-20 12:00:00+00:00"),
#     ("2023-01-03 00:00:00.001000+00:00 ", "2023-01-03 12:00:00+00:00"),
#     ("2023-01-06 12:00:00.001000+00:00 ", "2023-01-07 00:00:00+00:00"),
#     ("2023-01-07 12:00:00.001000+00:00 ", "2023-01-08 00:00:00+00:00"),
#     ("2023-01-08 12:00:00.001000+00:00 ", "2023-01-09 00:00:00+00:00"),
#     ("2023-01-30 00:00:00.001000+00:00 ", "2023-01-30 12:00:00+00:00"),
#     ("2023-02-02 12:00:00.001000+00:00 ", "2023-02-03 00:00:00+00:00"),
#     ("2023-02-15 12:00:00.001000+00:00 ", "2023-02-16 00:00:00+00:00"),
#     ("2023-04-01 12:00:00.001000+00:00 ", "2023-04-02 00:00:00+00:00"),
#     ("2023-06-16 12:00:00.001000+00:00 ", "2023-06-17 00:00:00+00:00"),
#     ("2023-10-14 12:00:00.001000+00:00 ", "2023-10-15 00:00:00+00:00"),
#     ("2023-11-27 00:00:00.001000+00:00 ", "2023-11-27 12:00:00+00:00"),
#     ("2024-02-18 00:00:00.001000+00:00 ", "2024-02-18 12:00:00+00:00"),
#     ("2024-02-19 12:00:00.001000+00:00 ", "2024-02-20 00:00:00+00:00"),
#     ("2024-04-05 12:00:00.001000+00:00 ", "2024-04-06 00:00:00+00:00"),
#     ("2024-04-29 12:00:00.001000+00:00 ", "2024-04-30 00:00:00+00:00"),
#     ("2024-10-05 12:00:00.001000+00:00 ", "2024-10-06 00:00:00+00:00"),
#     ("2024-10-14 12:00:00.001000+00:00 ", "2024-10-15 00:00:00+00:00"),
#     ("2024-11-03 00:00:00.001000+00:00 ", "2024-11-03 12:00:00+00:00")
# ]

# Where to save the resulting cache to 
CSV_FNAME = '/skyblue/cacheFixPickle.csv'
ERR_LOG_PATH = '/skyblue/cacheFixPickleErrorLog.txt'

def create_cache(start, end):
    """
    Creates a pickled cache of pireps from start to end with two columns
    'Timestamps' and 'Data' where Timestamps are the reports' tiemstamps,
    and 'Data' is the pickled reports

    Parameters
    ----------
    start: dt.datetime
        The start date (in UTC) to include PIREPs from
    end: dt.datetime
        The end data (in UTC) to include PIREPs to
    """
    print(f"Creating New Batch for {start} to {end}")
    reports = pr.parse_all(pr.fetch(pr.url(start, end)))


    # Rip out timestamps for each report
    timestamps = list(map(lambda r : r["Timestamp"], reports))


    # Convert to pd
    df = pd.DataFrame({
        "Timestamp" : timestamps,
        "Data"      : [pickle.dumps(r) for r in reports]     
    })
    
    df.to_csv(CSV_FNAME, mode = "a", header=False, index=False)



if __name__ == '__main__':
    if '--init' in sys.argv:
        df = pd.DataFrame({
                "Timestamp" : [],
                "Data"      : []
            })
        df.to_csv(CSV_FNAME, mode = "w", header=True, index=False)
    else:
        for start, end in erroredDates:
            curr_start = parser.parse(start)
            curr_end = curr_start + dt.timedelta(hours=1)
            final_end = parser.parse(end)
            
            with open(ERR_LOG_PATH, mode = 'a') as errFile:
                while curr_end < final_end:
                    try:
                        create_cache(curr_start, curr_end)
                    except Exception as e:
                        print(f"Issue creating cache on range: {curr_start} - {curr_end} with Error:\n {e}", file=errFile)
                    diff = dt.timedelta(hours=1)
                    curr_start = curr_end + dt.timedelta(milliseconds=1)
                    curr_end += diff
                try:
                    create_cache(curr_start, final_end)
                except Exception as e:
                    print(f"Issue creating cache on range: {curr_start} - {final_end} with Error:\n {e}", file=errFile)

